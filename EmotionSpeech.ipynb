{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMV0Hpywmi40Z4s0ZM4Hbwj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadipatodia/Speech-Emotion-Recognization/blob/main/EmotionSpeech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa soundfile numpy scikit-learn pandas"
      ],
      "metadata": {
        "id": "v3t1gMk4bNUi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "base_dir = '/content/dataset'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "zip_files = ['satisfied_calls.zip', 'unsatisfied_calls.zip', 'average_calls.zip']\n",
        "for zip_file in zip_files:\n",
        "  with zipfile.ZipFile(f'/content/{zip_file}', 'r') as zip_ref:\n",
        "        zip_ref.extractall(base_dir)"
      ],
      "metadata": {
        "id": "6s7Ccc1R0ja3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "AIM : To pocess audio files within a specific directory structure. It primarily focuses on converting.ulaw.wav files to standard .wav\n",
        "      format and then using librosa to inspect the converted (or original) .wav files\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import librosa                   # It's used here to load audio files and get their properties like sample rate and duration\n",
        "from pydub import AudioSegment   # for converting audio file formats.\n",
        "\n",
        "base_dir = '/content/dataset'\n",
        "folders = ['Average call quailty', 'Satisfied Call Quality', 'Not-Satisfied Call Quailty']    # subfolders within base_dir that contain\n",
        "\n",
        "for folder in folders:   # iterates through all 3 folders in dataset folder\n",
        "    data_dir = os.path.join(base_dir, folder)                  # This constructs the full path to the source directory for the current category.\n",
        "                                                               # For example, /content/dataset/Average call quailty\n",
        "    wav_dir_name = folder.replace(' ', '_').lower() + '_wav'   # standardized name for the output directory for converted WAV files\n",
        "    wav_dir = os.path.join(base_dir, wav_dir_name)\n",
        "    os.makedirs(wav_dir, exist_ok=True)                        # creates the wav_dir if it doesn't already exist. exist_ok=True prevents an\n",
        "                                                               # error if the directory already exists from a previous run.\n",
        "\n",
        "    # First, convert all .ulaw.wav files\n",
        "    for file in os.listdir(data_dir):   # iterates through each file in folder\n",
        "        if file.endswith('.ulaw.wav'):\n",
        "            input_path = os.path.join(data_dir, file)          # Constructs the full path to the input .ulaw.wav file.\n",
        "            output_path = os.path.join(wav_dir, file.replace('.ulaw.wav', '.wav'))\n",
        "            try:                        # This block attempts the conversion and catches any errors that might occur\n",
        "                audio = AudioSegment.from_file(input_path, format='wav')\n",
        "                audio.export(output_path, format='wav')\n",
        "                print(f\"Converted {input_path} to {output_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error converting {input_path}: {e}\")\n",
        "\n",
        "    # Then, process the converted .wav files (and any original .wav files)\n",
        "    for file in os.listdir(wav_dir):\n",
        "        if file.endswith('.wav'):\n",
        "            path = os.path.join(wav_dir, file)\n",
        "            try:                                 # This block attempts to load the audio file using librosa and extract its properties.\n",
        "                y, sr = librosa.load(path, sr=None)\n",
        "                print(f\"File: {path}, Sample rate: {sr} Hz, Duration: {librosa.get_duration(y=y, sr=sr)} seconds\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {path}: {e}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oSxmHXkf0tPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ec5226"
      },
      "source": [
        "!ls /content/dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re # Import regex for advanced string matching\n",
        "\n",
        "# Define base directory\n",
        "base_dir = '/content/dataset'\n",
        "csv_file_path = '/content/CallRecords.csv'\n",
        "\n",
        "# Initialize an empty DataFrame to store call records\n",
        "df_combined = pd.DataFrame(columns=[\"CALL RECORDING NUMBER\", \"CALL STATUS\"])\n",
        "\n",
        "## Feature 1, 2, 3: Read filenames from specific folders and populate DataFrame\n",
        "# Mapping of folder names to call statuses\n",
        "folder_to_status_map = {\n",
        "    'average_call_quailty_wav': 'Average',\n",
        "    'satisfied_call_quality_wav': 'Satisfied',\n",
        "    'not-satisfied_call_quailty_wav': 'Unsatisfied'\n",
        "}\n",
        "\n",
        "print(\"--- Populating CallRecords.csv from specific folders ---\")\n",
        "for folder, status in folder_to_status_map.items():\n",
        "    folder_path = os.path.join(base_dir, folder)\n",
        "    if os.path.exists(folder_path):\n",
        "        print(f\"Processing folder: {folder_path} for status: {status}\")\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith('.wav') or filename.endswith('.ulaw'): # Consider both formats\n",
        "                new_record = pd.DataFrame([{\"CALL RECORDING NUMBER\": filename, \"CALL STATUS\": status}])\n",
        "                df_combined = pd.concat([df_combined, new_record], ignore_index=True)\n",
        "    else:\n",
        "        print(f\"Warning: Directory '{folder_path}' not found. Skipping.\")\n",
        "\n",
        "## Feature 4: Read filenames from 'audio_data' and determine status from filename\n",
        "audio_data_dir = os.path.join(base_dir, 'audio_data')\n",
        "if os.path.exists(audio_data_dir):\n",
        "    print(f\"Processing folder: {audio_data_dir} for status extraction from filenames\")\n",
        "    for filename in os.listdir(audio_data_dir):\n",
        "        if filename.endswith('.wav') or filename.endswith('.ulaw'):\n",
        "            # Extract status from filename (e.g., 'recording-xxx-avg.wav')\n",
        "            match = re.search(r'-(avg|sat|unsat)\\.', filename)\n",
        "            call_status = None\n",
        "            if match:\n",
        "                status_code = match.group(1)\n",
        "                if status_code == 'avg':\n",
        "                    call_status = 'Average'\n",
        "                elif status_code == 'sat':\n",
        "                    call_status = 'Satisfied'\n",
        "                elif status_code == 'unsat':\n",
        "                    call_status = 'Unsatisfied'\n",
        "\n",
        "            if call_status:\n",
        "                new_record = pd.DataFrame([{\"CALL RECORDING NUMBER\": filename, \"CALL STATUS\": call_status}])\n",
        "                df_combined = pd.concat([df_combined, new_record], ignore_index=True)\n",
        "            else:\n",
        "                print(f\"Warning: Could not determine status for file: {filename} in {audio_data_dir}. Skipping.\")\n",
        "else:\n",
        "    print(f\"Warning: Directory '{audio_data_dir}' not found. Skipping.\")\n",
        "\n",
        "# Write the combined DataFrame to CSV\n",
        "df_combined.to_csv(csv_file_path, index=False)\n",
        "print(f\"\\nSuccessfully created/updated '{csv_file_path}' with {len(df_combined)} records.\")\n",
        "\n",
        "# --- Continue with the original code (modified to use the newly generated CSV) ---\n",
        "\n",
        "# Read CSV file\n",
        "df_csv = pd.read_csv(csv_file_path)\n",
        "\n",
        "df_csv.columns = df_csv.columns.str.strip().str.upper() # Standardizes column name and removes extra spaces etc\n",
        "df_csv['CALL STATUS'] = df_csv['CALL STATUS'].str.strip().str.upper() # Does the same for values inside CALL STATUS column\n",
        "\n",
        "# Verify column names\n",
        "print(\"\\nNormalized column names:\", df_csv.columns.tolist())\n",
        "column_name = 'CALL RECORDING NUMBER'\n",
        "if column_name not in df_csv.columns:\n",
        "    raise KeyError(f\"Column '{column_name}' not found. Available columns: {df_csv.columns.tolist()}\")\n",
        "\n",
        "def normalize_filename(filename_str): # function to standardize the recording filenames from the CSV.\n",
        "    # Convert to string first\n",
        "    filename_str = str(filename_str)\n",
        "    # Remove any existing .ulaw or .wav suffixes to start fresh\n",
        "    filename_str = filename_str.replace('.ulaw', '').replace('.wav', '')\n",
        "    # Add the desired .wav suffix\n",
        "    return filename_str + '.wav'\n",
        "\n",
        "df_csv[column_name] = df_csv[column_name].apply(normalize_filename)\n",
        "\n",
        "# Corrects potential misspellings and standardizes status names\n",
        "df_csv['CALL STATUS'] = df_csv['CALL STATUS'].replace('SATISIFED', 'SATISFIED')\n",
        "df_csv['CALL STATUS'] = df_csv['CALL STATUS'].replace('NOT SATISFIED', 'UNSATISFIED')\n",
        "\n",
        "status_to_parent = { # This links the CSV data to the physical file organization.\n",
        "    'SATISFIED': 'satisfied_call_quality_wav',\n",
        "    'UNSATISFIED': 'not-satisfied_call_quailty_wav',\n",
        "    'AVERAGE': 'average_call_quailty_wav'\n",
        "}\n",
        "\n",
        "# Add a specific mapping for audio_data directory\n",
        "# This assumes that if a file came from 'audio_data', its true parent should be 'audio_data'\n",
        "# This requires a slight adjustment in how the file path is constructed later.\n",
        "status_to_actual_folder = {\n",
        "    'SATISFIED': 'satisfied_call_quality_wav',\n",
        "    'UNSATISFIED': 'not-satisfied_call_quailty_wav',\n",
        "    'AVERAGE': 'average_call_quailty_wav'\n",
        "}\n",
        "\n",
        "\n",
        "# Create labels dictionary\n",
        "labels = {} # will store the final mappings\n",
        "# The keys will be the full paths to the audio files, and the values will be their assigned call status labels\n",
        "\n",
        "print(\"\\n--- Starting file matching ---\")\n",
        "for index, row in df_csv.iterrows():\n",
        "    status = row['CALL STATUS']\n",
        "    record_filename_csv = row[column_name] # e.g., 'recording-173-... .wav'\n",
        "    record_num_prefix = record_filename_csv.replace('.wav', '') # Get just the base name for matching\n",
        "\n",
        "    # Determine the *expected* folder based on the filename or status\n",
        "    # This is crucial for files that might originate from 'audio_data' but have a 'SATISFIED' status\n",
        "\n",
        "    # First, try to find the file in the specific status folders (satisfied_call_quality_wav, etc.)\n",
        "    parent_folder_name = status_to_parent.get(status)\n",
        "    possible_dirs = []\n",
        "\n",
        "    if parent_folder_name:\n",
        "        possible_dirs.append(os.path.join(base_dir, parent_folder_name))\n",
        "\n",
        "    # Always check the 'audio_data' directory as well, as files from there also get statuses\n",
        "    possible_dirs.append(os.path.join(base_dir, 'audio_data'))\n",
        "\n",
        "    found_match = False\n",
        "    for data_dir in possible_dirs:\n",
        "        if os.path.exists(data_dir):\n",
        "            for file_in_dir in os.listdir(data_dir):\n",
        "                if file_in_dir.endswith('.wav') and record_num_prefix in file_in_dir:\n",
        "                    # Construct the path relative to the base_dir for consistency\n",
        "                    filename_for_label = os.path.join(os.path.basename(base_dir), os.path.basename(data_dir), file_in_dir)\n",
        "                    labels[filename_for_label] = status\n",
        "                    found_match = True\n",
        "                    break # Found the file, move to the next row in CSV\n",
        "            if found_match:\n",
        "                break # Break from iterating possible_dirs if match found\n",
        "\n",
        "    if not found_match:\n",
        "        print(f\"No match found for CSV entry '{record_filename_csv}' with status '{status}' in any expected directory.\")\n",
        "\n",
        "# Display a sample\n",
        "print(\"\\nSample labels:\", list(labels.items())[:5])\n",
        "print(f\"\\nTotal labels created: {len(labels)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pc-Zj3Wn6lh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/labels.pkl', 'wb') as f:\n",
        "    pickle.dump(labels, f)"
      ],
      "metadata": {
        "id": "4MhzjEcUJ_zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import pickle\n",
        "\n",
        "def extract_features(file_path):    # It takes the path to an audio file and computes several common audio features.\n",
        "    y, sr = librosa.load(file_path, sr=None)    # sr = None preserves the original sample rate\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
        "    features = np.hstack([mfccs, chroma, mel])\n",
        "    return features\n",
        "\n",
        "base_dir_raw = '/content/dataset'\n",
        "segmented_dir = '/content/segmented_audio'\n",
        "os.makedirs(segmented_dir, exist_ok=True)\n",
        "\n",
        "labels = {}\n",
        "categories = ['average_call_quailty_wav', 'satisfied_call_quality_wav', 'not-satisfied_call_quailty_wav']\n",
        "\n",
        "for category in categories:\n",
        "# It walks through the original audio directories, identifies .wav files, and populates the labels dictionary with 'relative_path : category' mappings.\n",
        "    category_path = os.path.join(base_dir_raw, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        for root, _, files in os.walk(category_path):\n",
        "            for file in files:\n",
        "                if file.endswith('.wav'):\n",
        "                    relative_path = os.path.relpath(os.path.join(root, file), base_dir_raw)\n",
        "                    labels[relative_path] = category\n",
        "    else:\n",
        "        print(f\"Category directory not found: {category_path}\")\n",
        "\n",
        "processed_segment_info = []\n",
        "\n",
        "for filename, status in labels.items():\n",
        "    file_path = os.path.join(base_dir_raw, filename)\n",
        "    if os.path.exists(file_path):\n",
        "        try:\n",
        "            y, sr = librosa.load(file_path, sr=None)\n",
        "            duration = librosa.get_duration(y=y, sr=sr)\n",
        "            if duration >= 45:\n",
        "                start_sample = int(0 * sr)\n",
        "                end_sample = int((duration - 25) * sr)\n",
        "                start_samples_duration = int(20 * sr)\n",
        "                end_samples_duration = int(25 * sr)\n",
        "\n",
        "                start_segment = y[start_sample:start_sample + start_samples_duration]\n",
        "                end_segment = y[end_sample:end_sample + end_samples_duration]\n",
        "\n",
        "                original_subdir = os.path.basename(os.path.dirname(file_path))\n",
        "                output_category_dir = os.path.join(segmented_dir, original_subdir)\n",
        "                os.makedirs(output_category_dir, exist_ok=True)\n",
        "\n",
        "                base_name = os.path.splitext(os.path.basename(filename))[0]\n",
        "\n",
        "                for i, segment in enumerate([start_segment, end_segment]):\n",
        "                    segment_path = os.path.join(output_category_dir, f\"{base_name}_part{i+1}.wav\")\n",
        "                    sf.write(segment_path, segment, sr)\n",
        "                    print(f\"Saved {segment_path} for {filename} (Duration: {duration:.2f}s)\")\n",
        "\n",
        "                    processed_segment_info.append({\n",
        "                        'original_file': filename,\n",
        "                        'original_status': status,\n",
        "                        'segment_type': 'start' if i == 0 else 'end',\n",
        "                        'segment_path': segment_path,\n",
        "                        'sample_rate': sr,\n",
        "                        'duration_original_file': duration\n",
        "                    })\n",
        "            else:\n",
        "                print(f\"Skipping {filename}: Duration {duration:.2f} seconds is less than 45 seconds\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")\n",
        "    else:\n",
        "        print(f\"File {file_path} not found\")\n",
        "\n",
        "with open('/content/segments_info.pkl', 'wb') as f:\n",
        "    pickle.dump(processed_segment_info, f)\n",
        "\n",
        "print(\"Segment information successfully pickled to /content/segments_info.pkl\")\n",
        "\n",
        "# Feature extraction part\n",
        "base_dir_segmented = '/content/segmented_audio'\n",
        "# Defines the base directory where the segmented audio files are located.\n",
        "# This is where the script will now look for files to extract features from.\n",
        "feature_data = []    # empty list to store the extracted numerical feature vectors\n",
        "feature_labels = []  # empty list to store the corresponding category labels for each feature vector.\n",
        "\n",
        "if 'labels' not in locals():\n",
        "# This is a check to see if the labels dictionary (has the segmentation part) exists in the current script's local scope.\n",
        "    try:\n",
        "        with open('/content/segments_info.pkl', 'rb') as f:\n",
        "            loaded_segment_info = pickle.load(f)\n",
        "        labels = {info['original_file']: info['original_status'] for info in loaded_segment_info}\n",
        "        print(\"Labels loaded from /content/segments_info.pkl\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: segments_info.pkl not found. 'labels' variable is missing. Please run the segmentation part first or ensure the pickle file exists.\")\n",
        "        exit()\n",
        "\n",
        "for original_file_relative_path, category_name in labels.items():\n",
        "    file_base = os.path.splitext(os.path.basename(original_file_relative_path))[0]\n",
        "\n",
        "    segment_paths = [\n",
        "        os.path.join(base_dir_segmented, category_name, f\"{file_base}_part1.wav\"),\n",
        "        os.path.join(base_dir_segmented, category_name, f\"{file_base}_part2.wav\")\n",
        "    ]\n",
        "\n",
        "    for segment_path in segment_paths:\n",
        "        if os.path.exists(segment_path):\n",
        "            features = extract_features(segment_path)\n",
        "            feature_data.append(features)\n",
        "            feature_labels.append(category_name)\n",
        "            print(f\"Extracted features from {segment_path} (Label: {category_name})\")\n",
        "        else:\n",
        "            print(f\"Segment {segment_path} not found\")\n",
        "\n",
        "feature_data = np.array(feature_data) #\n",
        "feature_labels = np.array(feature_labels)\n",
        "\n",
        "np.save('/content/feature_data.npy', feature_data)\n",
        "# Saves the feature_data NumPy array to a binary file with a .npy extension.\n",
        "np.save('/content/feature_labels.npy', feature_labels)\n",
        "# Saves the feature_labels NumPy array to a .npy file.\n",
        "print(\"\\nFeatures saved to /content/feature_data.npy and /content/feature_labels.npy\")\n",
        "\n",
        "print(f\"\\nTotal features extracted: {len(feature_data)}\")\n",
        "print(f\"Feature shape: {feature_data.shape}\")\n",
        "\n",
        "with open('/content/features.pkl', 'wb') as f:\n",
        "    pickle.dump({'data': feature_data, 'labels': feature_labels}, f)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3hfiWxR2WDhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Purpose: Train a neural network classifier using the extracted features to predict call emotions, prioritizing the end segmentâ€™s performance."
      ],
      "metadata": {
        "id": "c2cS50TOaz6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier # It's used for supervised learning tasks, specifically classification,\n",
        "# where it learns to map input features to output classes by passing data through multiple layers of interconnected \"neurons.\"\n",
        "from sklearn.model_selection import train_test_split  # This function is used to divide your dataset into two subsets: a training set and a testing set.\n",
        "from sklearn.metrics import accuracy_score\n",
        "# It calculates the proportion of correctly classified instances (predictions) out of the total number of instances\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# : This is a data pre-processing tool used for standardization.\n",
        "# It transforms your data so that it has a mean of 0 and a standard deviation of 1\n",
        "import numpy as np\n",
        "import joblib # for parallel computing\n",
        "\n",
        "# Load features\n",
        "feature_data = np.load('/content/feature_data.npy')\n",
        "feature_labels = np.load('/content/feature_labels.npy')\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "feature_data = scaler.fit_transform(feature_data)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    feature_data, feature_labels, test_size=0.30, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize and train the model\n",
        "model = MLPClassifier(\n",
        "    hidden_layer_sizes=(100,), # 100 hidden layers\n",
        "    max_iter=300,\n",
        "    learning_rate_init=0.001,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Save the model and scaler\n",
        "joblib.dump(model, '/content/emotion_model.joblib')\n",
        "joblib.dump(scaler, '/content/scaler.joblib')\n",
        "print(\"Model and scaler saved to /content/emotion_model.joblib and /content/scaler.joblib\")"
      ],
      "metadata": {
        "id": "ERbNB8Yea0i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade librosa -q"
      ],
      "metadata": {
        "id": "7TWY-npQ2-0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print(\"Google Drive mounted.\")\n",
        "\n",
        "# Step 2: Create a local folder to store audio files and statuses\n",
        "folder_path = '/content/audio_data'\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "print(f\"Folder created at: {folder_path}\")\n",
        "\n",
        "# Step 3: Specify the Drive folder for form responses\n",
        "drive_folder = '/content/drive/MyDrive/ResponsesEmotionalSpeech/Please upload your audio file: (File responses)'\n",
        "if not os.path.exists(drive_folder):\n",
        "    raise FileNotFoundError(f\"Drive folder {drive_folder} not found. Please ensure the path is correct and files are present.\")\n",
        "\n",
        "# Step 4: Fetch Google Form responses from the linked spreadsheet\n",
        "spreadsheet_id = '1tnRV1iIJwg2Y5sipWUceh6ZudVr3fPwGpCtUL8KJISM'\n",
        "csv_url = f'https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=csv&gid=825495712'\n",
        "print(f\"Attempting to fetch CSV from: {csv_url}\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_url)\n",
        "    print(\"Form responses fetched successfully:\")\n",
        "    print(df)\n",
        "    # --- IMPORTANT DEBUG STEP ---\n",
        "    print(\"\\nDataFrame Column Names (Exact):\")\n",
        "    for col in df.columns:\n",
        "        print(f\"'{col}'\")\n",
        "    # --- END DEBUG STEP ---\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching spreadsheet: {str(e)}. This may be due to an invalid URL or access restrictions.\")\n",
        "    print(\"Please ensure the spreadsheet is shared with your Google account (edit access) and the ID/gid are correct.\")\n",
        "    raise\n",
        "\n",
        "# Step 5: List files in the Drive folder\n",
        "drive_files = os.listdir(drive_folder)\n",
        "print(f\"\\nFiles found in Drive folder '{drive_folder}': {drive_files}\")\n",
        "\n",
        "if not drive_files:\n",
        "    print(f\"Warning: The specified Google Drive folder '{drive_folder}' is empty. No audio files to process.\")\n",
        "\n",
        "# Strip whitespace from all column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Define the column names\n",
        "FILENAME_COLUMN = 'Please type the exact filename of your audio recording (e.g., my_speech.wav):'\n",
        "\n",
        "def generate_possible_filenames(original_name, drive_files_list):\n",
        "    name_part, ext_part = os.path.splitext(original_name)\n",
        "    possible_names = [original_name]\n",
        "\n",
        "    for drive_file in drive_files_list:\n",
        "        if drive_file.startswith(name_part) and drive_file.endswith(ext_part):\n",
        "            if drive_file == original_name:\n",
        "                continue\n",
        "\n",
        "            if ' - ' in drive_file:\n",
        "                parts = drive_file.split(' - ')\n",
        "                if len(parts) > 1 and parts[0] == name_part:\n",
        "                    uploader_name_with_ext = parts[1]\n",
        "                    uploader_name = os.path.splitext(uploader_name_with_ext)[0].split(' (')[0]\n",
        "                    possible_names.append(f\"{name_part} - {uploader_name}{ext_part}\")\n",
        "                    for i in range(1, 10):\n",
        "                        possible_names.append(f\"{name_part} - {uploader_name} ({i}){ext_part}\")\n",
        "\n",
        "    return list(set(possible_names))\n",
        "\n",
        "# Function to generate the new filename with suffix\n",
        "def rename_file(original_name, status):\n",
        "    name_part, ext_part = os.path.splitext(original_name)\n",
        "\n",
        "    # Remove everything after the first \"-\" if it exists, but before the extension\n",
        "    if '-' in name_part:\n",
        "        name_part = name_part.split('-')[0].strip() # Takes \"audio - Aadi (1)\" and makes it \"audio\"\n",
        "\n",
        "    # Add suffix based on status\n",
        "    suffix = {\n",
        "        'Average': 'avg',\n",
        "        'Satisfied': 'sat',\n",
        "        'Unsatisfied': 'unsat'\n",
        "    }.get(status, '')  # Default to empty string if status not recognized\n",
        "\n",
        "    if suffix:\n",
        "        name_part = f\"{name_part}-{suffix}\"\n",
        "\n",
        "    return f\"{name_part}{ext_part}\"\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    form_audio_url = row['Please upload your audio file:']\n",
        "    status = row.get('Choose one of the following:', 'Not provided')\n",
        "\n",
        "    user_provided_filename = row.get(FILENAME_COLUMN)\n",
        "\n",
        "    if pd.isna(user_provided_filename) or user_provided_filename == '':\n",
        "        print(f\"Skipping row {index}: User-provided filename is missing or empty in the spreadsheet.\")\n",
        "        continue\n",
        "\n",
        "    if pd.isna(form_audio_url):\n",
        "        print(f\"Skipping row {index}: Audio file URL is missing.\")\n",
        "        continue\n",
        "\n",
        "    matched_file = None\n",
        "\n",
        "    potential_filenames = generate_possible_filenames(user_provided_filename, drive_files)\n",
        "\n",
        "    for p_name in potential_filenames:\n",
        "        if p_name in drive_files:\n",
        "            matched_file = p_name\n",
        "            break\n",
        "\n",
        "    if not matched_file and user_provided_filename in drive_files:\n",
        "        matched_file = user_provided_filename\n",
        "\n",
        "    if matched_file:\n",
        "        drive_file_path = os.path.join(drive_folder, matched_file)\n",
        "        # Generate new filename based on status\n",
        "        new_filename = rename_file(matched_file, status)\n",
        "        dest_path = os.path.join(folder_path, new_filename)\n",
        "\n",
        "        if os.path.exists(drive_file_path):\n",
        "            shutil.copy(drive_file_path, dest_path)\n",
        "            # Removed the status file creation\n",
        "            print(f\"Copied '{matched_file}' to '{folder_path}' as '{new_filename}' with status: {status}\")\n",
        "        else:\n",
        "            print(f\"Error: Matched file '{matched_file}' was supposed to be at '{drive_file_path}' but was not found. Sync issue?\")\n",
        "    else:\n",
        "        print(f\"Could not find a matching file in Drive for form entry (row {index}).\")\n",
        "        print(f\"    User-provided filename: '{user_provided_filename}'\")\n",
        "        print(f\"    Tried matching against potential names: {potential_filenames}\")\n",
        "        print(f\"    Files found in Drive folder: {drive_files}\")\n",
        "\n",
        "print(\"\\nContents of audio_data folder:\")\n",
        "print(os.listdir(folder_path))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6ArFsCPaYPZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update our ear toy (librosa) quietly\n",
        "!pip install --upgrade librosa -q\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Load the trained model and scaler\n",
        "model_path = '/content/emotion_model.joblib'\n",
        "scaler_path = '/content/scaler.joblib'\n",
        "if not os.path.exists(model_path) or not os.path.exists(scaler_path):\n",
        "    raise FileNotFoundError(\"Model or scaler files not found. Please ensure they are saved from Step 6.\")\n",
        "model = joblib.load(model_path)\n",
        "scaler = joblib.load(scaler_path)\n",
        "\n",
        "# Function to extract features\n",
        "def extract_features(y, sr):\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
        "    return np.hstack([mfccs, chroma, mel])\n",
        "\n",
        "# Map predictions to readable labels\n",
        "emotion_map = {\n",
        "    'satisfied_wav': 'SATISFIED',\n",
        "    'unsatisfied_wav': 'UNSATISFIED',\n",
        "    'average_call_quailty_wav': 'AVERAGE'\n",
        "}\n",
        "\n",
        "# Map filename suffixes to expected emotions\n",
        "suffix_map = {\n",
        "    'avg': 'AVERAGE',\n",
        "    'sat': 'SATISFIED',\n",
        "    'unsat': 'UNSATISFIED'\n",
        "}\n",
        "\n",
        "# Process all audio files in the folder\n",
        "audio_folder = '/content/audio_data'\n",
        "if not os.path.exists(audio_folder):\n",
        "    raise FileNotFoundError(f\"Audio folder not found at {audio_folder}. Please ensure the folder exists and contains .wav files.\")\n",
        "\n",
        "audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.wav')]\n",
        "if not audio_files:\n",
        "    print(f\"No .wav files found in {audio_folder}.\")\n",
        "else:\n",
        "    # Initial predictions\n",
        "    initial_results = {}\n",
        "    feature_data = np.load('/content/feature_data.npy') if os.path.exists('/content/feature_data.npy') else np.array([])\n",
        "    feature_labels = np.load('/content/feature_labels.npy') if os.path.exists('/content/feature_labels.npy') else np.array([])\n",
        "\n",
        "    for audio_file in audio_files:\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        try:\n",
        "            y, sr = librosa.load(audio_path, sr=None)\n",
        "            duration = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "            if duration >= 20:\n",
        "                y_start = y[:int(20 * sr)]\n",
        "                start_features = extract_features(y_start, sr)\n",
        "                start_features = scaler.transform(start_features.reshape(1, -1))\n",
        "                start_pred = model.predict(start_features)[0]\n",
        "                start_emotion = emotion_map.get(start_pred.lower().replace('_part1', '').replace('_part2', ''), start_pred)\n",
        "            else:\n",
        "                start_emotion = \"Too short for 20s analysis!\"\n",
        "\n",
        "            if duration >= 25:\n",
        "                y_end = y[int(-25 * sr):] if duration > 25 else y\n",
        "                end_features = extract_features(y_end, sr)\n",
        "                end_features = scaler.transform(end_features.reshape(1, -1))\n",
        "                end_pred = model.predict(end_features)[0]\n",
        "                end_emotion = emotion_map.get(end_pred.lower().replace('_part1', '').replace('_part2', ''), end_pred)\n",
        "            else:\n",
        "                end_emotion = \"Too short for 25s analysis!\"\n",
        "\n",
        "            initial_results[audio_file] = {'start': start_emotion, 'end': end_emotion}\n",
        "            print(f\"File: {audio_file}\")\n",
        "            print(f\"First 20 seconds emotion: {start_emotion}\")\n",
        "            print(f\"Last 25 seconds emotion: {end_emotion}\")\n",
        "\n",
        "            # Check and collect data for retraining\n",
        "            name_part = os.path.splitext(audio_file)[0]\n",
        "            expected_emotion = None\n",
        "            for suffix, emotion in suffix_map.items():\n",
        "                if f'-{suffix}' in name_part:\n",
        "                    expected_emotion = emotion\n",
        "                    break\n",
        "\n",
        "            if expected_emotion and duration >= 25 and end_emotion != expected_emotion and end_emotion not in [\"Too short for 25s analysis!\"]:\n",
        "                print(f\"Mismatch detected! Expected: {expected_emotion}, Predicted: {end_emotion}\")\n",
        "                new_end_features = extract_features(y_end, sr)\n",
        "                feature_data = np.vstack([feature_data, new_end_features.reshape(1, -1)]) if feature_data.size else new_end_features.reshape(1, -1)\n",
        "                feature_labels = np.append(feature_labels, expected_emotion) if feature_labels.size else np.array([expected_emotion])\n",
        "            elif expected_emotion:\n",
        "                print(f\"Classification matches expected emotion: {expected_emotion}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {audio_file}: {str(e)}\")\n",
        "            print(\"-\" * 50)\n",
        "            continue\n",
        "\n",
        "    # Retrain the model if new data was added\n",
        "    if feature_data.size and feature_labels.size:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            feature_data, feature_labels, test_size=0.1, random_state=42\n",
        "        )\n",
        "\n",
        "        model = MLPClassifier(\n",
        "            hidden_layer_sizes=(120,),\n",
        "            max_iter=1000,  # Increased iterations for better convergence\n",
        "            learning_rate_init=0.0005,\n",
        "            random_state=42\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Re-evaluate all files with the retrained model\n",
        "        print(\"\\nRe-evaluating all files with retrained model:\")\n",
        "        for audio_file in audio_files:\n",
        "            audio_path = os.path.join(audio_folder, audio_file)\n",
        "            try:\n",
        "                y, sr = librosa.load(audio_path, sr=None)\n",
        "                duration = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "                if duration >= 20:\n",
        "                    y_start = y[:int(20 * sr)]\n",
        "                    start_features = extract_features(y_start, sr)\n",
        "                    start_features = scaler.transform(start_features.reshape(1, -1))\n",
        "                    start_pred = model.predict(start_features)[0]\n",
        "                    start_emotion = emotion_map.get(start_pred.lower().replace('_part1', '').replace('_part2', ''), start_pred)\n",
        "                else:\n",
        "                    start_emotion = initial_results[audio_file]['start']\n",
        "\n",
        "                if duration >= 25:\n",
        "                    y_end = y[int(-25 * sr):] if duration > 25 else y\n",
        "                    end_features = extract_features(y_end, sr)\n",
        "                    end_features = scaler.transform(end_features.reshape(1, -1))\n",
        "                    end_pred = model.predict(end_features)[0]\n",
        "                    end_emotion = emotion_map.get(end_pred.lower().replace('_part1', '').replace('_part2', ''), end_pred)\n",
        "                else:\n",
        "                    end_emotion = initial_results[audio_file]['end']\n",
        "\n",
        "                print(f\"File: {audio_file}\")\n",
        "                print(f\"Updated First 20 seconds emotion: {start_emotion}\")\n",
        "                print(f\"Updated Last 25 seconds emotion: {end_emotion}\")\n",
        "\n",
        "                name_part = os.path.splitext(audio_file)[0]\n",
        "                expected_emotion = next((emotion for suffix, emotion in suffix_map.items() if f'-{suffix}' in name_part), None)\n",
        "                if expected_emotion and duration >= 25:\n",
        "                    if end_emotion != expected_emotion and end_emotion not in [\"Too short for 25s analysis!\"]:\n",
        "                        print(f\"Retrained model still has mismatch! Expected: {expected_emotion}, Predicted: {end_emotion}\")\n",
        "                    else:\n",
        "                        print(f\"Retrained model matches expected emotion: {expected_emotion}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error re-evaluating {audio_file}: {str(e)}\")\n",
        "                print(\"-\" * 50)\n",
        "                continue\n",
        "\n",
        "        # Save updated data and model\n",
        "        np.save('/content/feature_data_updated.npy', feature_data)\n",
        "        np.save('/content/feature_labels_updated.npy', feature_labels)\n",
        "        joblib.dump(model, '/content/emotion_model_epic_retrained.joblib')\n",
        "        joblib.dump(scaler, '/content/scaler_epic_retrained.joblib')\n",
        "        print(\"Model retrained and saved as /content/emotion_model_epic_retrained.joblib with updated data.\")\n",
        "    else:\n",
        "        print(\"No new data for retraining. Model remains unchanged.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SgqFnl0y_TMd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}